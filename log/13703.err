{ 'action': 'train',
  'backprop_pcm': False,
  'config_folder': 'train2',
  'config_num': 129,
  'correlation_loss': False,
  'dataset': 'drum',
  'decoder': 'transformer',
  'device': device(type='cuda'),
  'l1': 'True',
  'l2': 'False',
  'loss_normalization': 'scalar_norm',
  'mask_activation': 'sigmoid',
  'model_lr': 0.001,
  'n_decoder_layers': 6,
  'n_heads': 2,
  'n_hidden_units': 100,
  'n_latents': 100,
  'n_test_epochs': 50000,
  'n_train_epochs': 50000,
  'test_batch_size': 3,
  'test_latents_Adam_lr': 0.001,
  'test_latents_init': 'normal',
  'train_batch_size': 32,
  'train_latents_Adam_lr': 0.001,
  'train_latents_init': 'normal'}
making Transformer Decoder
/home/xiaoyam/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1350: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
Epoch 1 - Average loss: 1.000000, Cumulative loss: 62.000000, Average Unnormed loss: 60.696371, Best Loss: 60.696371, Best Loss at Epoch 1(7.04 s)
slurmstepd: error: *** JOB 13703 ON compute-0-37 CANCELLED AT 2019-08-20T05:01:25 ***
